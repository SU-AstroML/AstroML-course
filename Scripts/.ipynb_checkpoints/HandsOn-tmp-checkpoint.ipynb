{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab\n",
      "import scipy.stats as sps\n",
      "from astroML.plotting import setup_text_plots\n",
      "setup_text_plots(fontsize=8, usetex=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: TkAgg\n",
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 100000\n",
      "x_max = 120\n",
      "gauss = np.random.normal(100., 15.0, size=N)\n",
      "trunc_gauss = np.array([x for x in gauss if x >x_max])\n",
      "plt.hist(gauss, bins=100, normed=True)\n",
      "plt.hist(trunc_gauss, bins=100, normed=True)\n",
      "mu = gauss.mean()\n",
      "sigma = gauss.std()\n",
      "print 'mu: ', mu, 'sigma: ', sigma, '\\n', 'Truncated mean: ', trunc_gauss.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mu:  100.055649687 $\\sigma$:  15.0554500316 \n",
        "Truncated mean:  127.019099236\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dof = 100.\n",
      "dist = sps.chi2(dof)\n",
      "r = dist.rvs(10000)\n",
      "p = np.array([dist.pdf(x) for x in r])\n",
      "c = np.array([dist.cdf(x) for x in r])\n",
      "\n",
      "print r.mean(), r.std(), '(', sqrt(2.*dof), ')'\n",
      "chi2_dof = np.sum(p)/dof\n",
      "print chi2_dof"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100.230296659 14.1286860837 ( 14.1421356237 )\n",
        "2.01019235968\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "axpdf = fig.add_subplot(121)\n",
      "axpdf.hist(r, bins=100, normed=True)\n",
      "axpdf.plot(r, p, '.')\n",
      "axcdf = fig.add_subplot(122)\n",
      "axcdf.plot(r, c, '.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f3153b5d790>]"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 10000\n",
      "OUTLIERS = False\n",
      "out_frac = 0.05\n",
      "dof = N - 1\n",
      "xi = np.random.normal(100, 15, size=N)\n",
      "if OUTLIERS:\n",
      "    outliers = np.random.random(N*out_frac)*np.max(xi)\n",
      "    xi = np.append(xi, outliers)\n",
      "mu = xi.mean()\n",
      "plt.hist(xi, bins=100, alpha=0.5, normed=True)\n",
      "print 'data mean = ', mu\n",
      "sigma = 15.\n",
      "sig = sqrt(2./dof)\n",
      "print sigma, sig\n",
      "zi = (xi-mu)/sigma\n",
      "chi2_dof = 1./(dof)*np.sum(zi**2)\n",
      "#I don't understand what nsigma is here!\n",
      "nsig = (chi2_dof - 1) / sig\n",
      "nsigma = (chi2_dof - 1) / sigma\n",
      "print 'chi2/dof = ', chi2_dof, '(', nsig, ')'\n",
      "print 'chi2/dof = ', chi2_dof, '(', nsigma, ')'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data mean =  99.7450778151\n",
        "15.0 0.0141428427835\n",
        "chi2/dof =  0.98192770343 ( -1.27784044883 )\n",
        "chi2/dof =  0.98192770343 ( -0.00120481977135 )\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Figure 4.1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate Dataset\n",
      "np.random.seed(1)\n",
      "N = 50\n",
      "L0 = 10\n",
      "dL = 0.2\n",
      "t = np.linspace(0, 1, N)\n",
      "L_obs = np.random.normal(L0, dL, N)\n",
      "\n",
      "# Plot the results\n",
      "fig = plt.figure(figsize=(5, 5))\n",
      "fig.subplots_adjust(left=0.1, right=0.95, wspace=0.05,\n",
      "                    bottom=0.1, top=0.95, hspace=0.05)\n",
      "y_vals = [L_obs, L_obs, L_obs, L_obs + 0.5 - t ** 2]\n",
      "y_errs = [dL, dL * 2, dL / 2, dL]\n",
      "titles = ['correct errors',\n",
      "          'overestimated errors',\n",
      "          'underestimated errors',\n",
      "          'incorrect model']\n",
      "\n",
      "for i in range(4):\n",
      "    ax = fig.add_subplot(2, 2, 1 + i, xticks=[])\n",
      "\n",
      "    # compute the mean and the chi^2/dof\n",
      "    mu = np.mean(y_vals[i])\n",
      "    z = (y_vals[i] - mu) / y_errs[i]\n",
      "    chi2 = np.sum(z ** 2)\n",
      "    chi2dof = chi2 / (N - 1)\n",
      "\n",
      "    # compute the standard deviations of chi^2/dof\n",
      "    sigma = np.sqrt(2. / (N - 1))\n",
      "    nsig = (chi2dof - 1) / sigma\n",
      "\n",
      "    # plot the points with errorbars\n",
      "    ax.errorbar(t, y_vals[i], y_errs[i], fmt='.k', ecolor='gray', lw=1)\n",
      "    ax.plot([-0.1, 1.3], [L0, L0], ':k', lw=1)\n",
      "\n",
      "    # Add labels and text\n",
      "    ax.text(0.95, 0.95, titles[i], ha='right', va='top',\n",
      "            transform=ax.transAxes,\n",
      "            bbox=dict(boxstyle='round', fc='w', ec='k'))\n",
      "    ax.text(0.02, 0.02, r'$\\hat{\\mu} = %.2f$' % mu, ha='left', va='bottom',\n",
      "            transform=ax.transAxes)\n",
      "    ax.text(0.98, 0.02,\n",
      "            r'$\\chi^2_{\\rm dof} = %.2f\\, (%.2g\\,\\sigma)$' % (chi2dof, nsig),\n",
      "            ha='right', va='bottom', transform=ax.transAxes)\n",
      "\n",
      "    # set axis limits\n",
      "    ax.set_xlim(-0.05, 1.05)\n",
      "    ax.set_ylim(8.6, 11.4)\n",
      "\n",
      "    # set ticks and labels\n",
      "    ax.yaxis.set_major_locator(plt.MultipleLocator(1))\n",
      "\n",
      "    if i > 1:\n",
      "        ax.set_xlabel('observations')\n",
      "\n",
      "    if i % 2 == 0:\n",
      "        ax.set_ylabel('Luminosity')\n",
      "    else:\n",
      "        ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Model comparison - Aikake information criterion (AIC)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If Likelihood dist. Gaussin: L0 dist. Chi2\n",
      "L0_dist = sps.chi2(100)\n",
      "L0 = L0_dist.rvs(1000) #if we have 100 models to compare\n",
      "N = np.ones_like(L0)*1000. #number of datapoints\n",
      "k = np.array([int(x) for x in np.random.uniform(2, 10, 1000)])\n",
      "AIC = -2.*np.log(L0) + 2*k + 2*k*(k+1)/(N-k-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(L0, bins=100, alpha=0.1)\n",
      "plt.scatter(L0, AIC, c=k, marker='o', edgecolor='None', cmap=cm.RdPu_r)\n",
      "plt.colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<matplotlib.colorbar.Colorbar instance at 0x7ff0a6428248>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Goodness of fit"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy import stats\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Figure 4.2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      "from sklearn.mixture import GMM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up the dataset.\n",
      "#  We'll use scikit-learn's Gaussian Mixture Model to sample\n",
      "#  data from a mixture of Gaussians.  The usual way of using\n",
      "#  this involves fitting the mixture to data: we'll see that\n",
      "#  below.  Here we'll set the internal means, covariances,\n",
      "#  and weights by-hand.\n",
      "np.random.seed(1)\n",
      "\n",
      "gmm = GMM(3, n_iter=1)\n",
      "gmm.means_ = np.array([[-1], [0], [3]])\n",
      "gmm.covars_ = np.array([[1.5], [1], [0.5]]) ** 2\n",
      "gmm.weights_ = np.array([0.3, 0.5, 0.2])\n",
      "\n",
      "X = gmm.sample(1000)\n",
      "np.shape(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "(1000, 1)"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Learn the best-fit GMM models\n",
      "#  Here we'll use GMM in the standard way: the fit() method\n",
      "#  uses an Expectation-Maximization approach to find the best\n",
      "#  mixture of Gaussians for the data\n",
      "\n",
      "# fit models with 1-10 components\n",
      "N = np.arange(1, 11)\n",
      "models = [None for i in range(len(N))]\n",
      "results = [False for i in range(len(N))]\n",
      "\n",
      "for i in range(len(N)):\n",
      "    models[i] = GMM(N[i]).fit(X)\n",
      "    results[i] = models[i].converged_\n",
      "\n",
      "# compute the AIC and the BIC\n",
      "AIC = [m.aic(X) for m in models]\n",
      "BIC = [m.bic(X) for m in models] #Bayesian information Criterion\n",
      "#plt.plot(N, AIC, 'r', label='AIC')\n",
      "#plt.plot(N, BIC, 'g', label='BIC')\n",
      "#plt.legend()\n",
      "print results\n",
      "M_bestA = models[np.argmin(AIC)]\n",
      "M_bestB = models[np.argmin(BIC)]\n",
      "M_bestA is M_bestB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[True, True, True, True, True, True, True, True, True, True]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the results\n",
      "#  We'll use three panels:\n",
      "#   1) data + best-fit mixture\n",
      "#   2) AIC and BIC vs number of components\n",
      "#   3) probability that a point came from each component\n",
      "\n",
      "fig = plt.figure(figsize=(5, 1.7))\n",
      "fig.subplots_adjust(left=0.12, right=0.97,\n",
      "                    bottom=0.21, top=0.9, wspace=0.5)\n",
      "\n",
      "\n",
      "# plot 1: data + best-fit mixture\n",
      "ax = fig.add_subplot(131)\n",
      "M_best = models[np.argmin(AIC)]\n",
      "\n",
      "x = np.linspace(-6, 6, 1000)\n",
      "logprob, responsibilities = M_best.eval(x) ##The is no such method on a GMM object!\n",
      "pdf = np.exp(logprob)\n",
      "pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
      "\n",
      "ax.hist(X, 30, normed=True, histtype='stepfilled', alpha=0.4)\n",
      "ax.plot(x, pdf, '-k')\n",
      "ax.plot(x, pdf_individual, '--k')\n",
      "ax.text(0.04, 0.96, \"Best-fit Mixture\",\n",
      "        ha='left', va='top', transform=ax.transAxes)\n",
      "ax.set_xlabel('$x$')\n",
      "ax.set_ylabel('$p(x)$')\n",
      "\n",
      "\n",
      "# plot 2: AIC and BIC\n",
      "ax = fig.add_subplot(132)\n",
      "ax.plot(N, AIC, '-k', label='AIC')\n",
      "ax.plot(N, BIC, '--k', label='BIC')\n",
      "ax.set_xlabel('n. components')\n",
      "ax.set_ylabel('information criterion')\n",
      "ax.legend(loc=2)\n",
      "\n",
      "\n",
      "# plot 3: posterior probabilities for each component\n",
      "ax = fig.add_subplot(133)\n",
      "\n",
      "p = M_best.predict_proba(x)\n",
      "p = p[:, (1, 0, 2)]  # rearrange order so the plot looks better\n",
      "p = p.cumsum(1).T\n",
      "\n",
      "ax.fill_between(x, 0, p[0], color='gray', alpha=0.3)\n",
      "ax.fill_between(x, p[0], p[1], color='gray', alpha=0.5)\n",
      "ax.fill_between(x, p[1], 1, color='gray', alpha=0.7)\n",
      "ax.set_xlim(-6, 6)\n",
      "ax.set_ylim(0, 1)\n",
      "ax.set_xlabel('$x$')\n",
      "ax.set_ylabel(r'$p({\\rm class}|x)$')\n",
      "\n",
      "ax.text(-5, 0.3, 'class 1', rotation='vertical')\n",
      "ax.text(0, 0.5, 'class 2', rotation='vertical')\n",
      "ax.text(3, 0.3, 'class 3', rotation='vertical')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'GMM' object has no attribute 'eval'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-34-eca4f3cf81b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponsibilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mpdf_individual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponsibilities\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'GMM' object has no attribute 'eval'"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}